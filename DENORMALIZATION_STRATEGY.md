# Denormalization Strategy - Hybrid Approach
## Performance Optimization for 5000 Peak Concurrent Users

---

## üìã Executive Summary

**Approach:** Hybrid denormalization using both real-time triggers and materialized views
**Database:** 100% Postgres (no MongoDB)
**Target Load:** 5000 concurrent users
**Goal:** Sub-200ms page load times across all priority pages

**Strategy:**
- **Real-time Pages:** Separate denormalized tables + triggers for instant updates
- **Eventually Consistent Pages:** Materialized views + event-driven refresh triggers
- **Refresh Policy:** All materialized views refresh on source data changes (not scheduled)

---

## üéØ Page Classification

### Category A: Real-Time (Trigger-Based Tables)
**Requirement:** Immediate consistency, updates must reflect instantly

| Page/Feature | Why Real-Time | Update Frequency |
|-------------|---------------|------------------|
| Direct Messages | User expectations for instant messaging | Very High |
| Intros (Requests/Responses) | Business-critical, time-sensitive | High |
| Dashboard (My Stats) | Personal data, must be accurate | High |
| My Projects | User's own content, expects instant updates | High |
| Notifications | Real-time alerts critical for UX | Very High |
| Unread Counts (Messages/Notifs) | Must be accurate for badges | Very High |

### Category B: Eventually Consistent (Materialized Views)
**Requirement:** Fast reads, updates can be 1-5 seconds delayed

| Page/Feature | Why Eventually Consistent | Refresh Trigger |
|-------------|---------------------------|-----------------|
| Feed (Trending/Top-Rated/Newest) | Public data, slight delay acceptable | On project vote/badge/comment |
| Leaderboards (Projects/Builders) | Rankings updated on events | On badge award/karma change |
| Chains List | Public discovery, can be slightly stale | On chain create/update/project add |
| Investors Directory | Public listings, low update frequency | On investor request status change |
| Search Results | Aggregated data, can be indexed | On project/user updates |
| Chain Details Page | Public content, moderate updates | On chain update/post create |
| Chain Forums (Posts) | Discussion threads, can lag slightly | On post/comment create |
| Project Details (Comments) | Public view, can be slightly stale | On comment create/edit |
| Admin Dashboard | Reports/analytics, real-time not critical | On key events (feedback, reports) |
| Investor Dashboard | Portfolio view, can be eventually consistent | On intro request changes |
| Validator Dashboard | Badge stats, can be slightly delayed | On badge award |
| User Profile (Public) | Public view, low update frequency | On user update/karma change |

---

## üóÑÔ∏è Real-Time Denormalized Tables (Category A)

### 1. User Dashboard Stats (`user_dashboard_stats`)
**Purpose:** Pre-compute all dashboard stats for instant load

```sql
CREATE TABLE user_dashboard_stats (
    user_id UUID PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE,

    -- Project stats
    project_count INT DEFAULT 0,
    active_projects INT DEFAULT 0,
    total_proof_score INT DEFAULT 0,

    -- Engagement stats
    comment_count INT DEFAULT 0,
    badges_given INT DEFAULT 0,
    badges_received INT DEFAULT 0,

    -- Intro stats
    intros_sent INT DEFAULT 0,
    intros_received INT DEFAULT 0,
    intro_requests_pending INT DEFAULT 0,

    -- Karma/Score
    karma_score INT DEFAULT 0,

    -- Unread counts
    unread_messages INT DEFAULT 0,
    unread_notifications INT DEFAULT 0,

    -- Timestamps
    last_updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- Indexes
    CONSTRAINT check_non_negative CHECK (
        project_count >= 0 AND active_projects >= 0 AND
        comment_count >= 0 AND karma_score >= 0
    )
);

CREATE INDEX idx_dashboard_stats_karma ON user_dashboard_stats(karma_score DESC);
CREATE INDEX idx_dashboard_stats_proof ON user_dashboard_stats(total_proof_score DESC);
```

**Triggers:**
```sql
-- Trigger 1: On project create/delete
CREATE OR REPLACE FUNCTION update_dashboard_project_stats()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' AND NEW.is_deleted = FALSE THEN
        UPDATE user_dashboard_stats
        SET project_count = project_count + 1,
            active_projects = active_projects + 1,
            last_updated_at = CURRENT_TIMESTAMP
        WHERE user_id = NEW.user_id;
    ELSIF TG_OP = 'UPDATE' THEN
        IF OLD.is_deleted = FALSE AND NEW.is_deleted = TRUE THEN
            UPDATE user_dashboard_stats
            SET active_projects = active_projects - 1,
                last_updated_at = CURRENT_TIMESTAMP
            WHERE user_id = NEW.user_id;
        END IF;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_dashboard_project_stats
AFTER INSERT OR UPDATE ON projects
FOR EACH ROW EXECUTE FUNCTION update_dashboard_project_stats();

-- Trigger 2: On badge award
CREATE OR REPLACE FUNCTION update_dashboard_badge_stats()
RETURNS TRIGGER AS $$
BEGIN
    -- Update validator stats (badges given)
    UPDATE user_dashboard_stats
    SET badges_given = badges_given + 1,
        last_updated_at = CURRENT_TIMESTAMP
    WHERE user_id = NEW.validator_id;

    -- Update project owner stats (badges received)
    UPDATE user_dashboard_stats
    SET badges_received = badges_received + 1,
        total_proof_score = (
            SELECT COALESCE(SUM(proof_score), 0)
            FROM projects
            WHERE user_id = (SELECT user_id FROM projects WHERE id = NEW.project_id)
              AND is_deleted = FALSE
        ),
        last_updated_at = CURRENT_TIMESTAMP
    WHERE user_id = (SELECT user_id FROM projects WHERE id = NEW.project_id);

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_dashboard_badge_stats
AFTER INSERT ON validation_badges
FOR EACH ROW EXECUTE FUNCTION update_dashboard_badge_stats();

-- Trigger 3: On message read/unread
CREATE OR REPLACE FUNCTION update_dashboard_message_count()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        UPDATE user_dashboard_stats
        SET unread_messages = unread_messages + 1,
            last_updated_at = CURRENT_TIMESTAMP
        WHERE user_id = NEW.recipient_id;
    ELSIF TG_OP = 'UPDATE' AND OLD.is_read = FALSE AND NEW.is_read = TRUE THEN
        UPDATE user_dashboard_stats
        SET unread_messages = GREATEST(0, unread_messages - 1),
            last_updated_at = CURRENT_TIMESTAMP
        WHERE user_id = NEW.recipient_id;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_dashboard_message_count
AFTER INSERT OR UPDATE ON direct_messages
FOR EACH ROW EXECUTE FUNCTION update_dashboard_message_count();

-- Trigger 4: On notification read/unread
CREATE OR REPLACE FUNCTION update_dashboard_notification_count()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        UPDATE user_dashboard_stats
        SET unread_notifications = unread_notifications + 1,
            last_updated_at = CURRENT_TIMESTAMP
        WHERE user_id = NEW.user_id;
    ELSIF TG_OP = 'UPDATE' AND OLD.is_read = FALSE AND NEW.is_read = TRUE THEN
        UPDATE user_dashboard_stats
        SET unread_notifications = GREATEST(0, unread_notifications - 1),
            last_updated_at = CURRENT_TIMESTAMP
        WHERE user_id = NEW.user_id;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_dashboard_notification_count
AFTER INSERT OR UPDATE ON notifications
FOR EACH ROW EXECUTE FUNCTION update_dashboard_notification_count();
```

---

### 2. Message Conversation List (`message_conversations_denorm`)
**Purpose:** Pre-compute conversation metadata for instant inbox load

```sql
CREATE TABLE message_conversations_denorm (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    other_user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,

    -- Last message info
    last_message_id UUID REFERENCES direct_messages(id) ON DELETE CASCADE,
    last_message_text TEXT,
    last_message_time TIMESTAMP,
    last_sender_id UUID REFERENCES users(id),

    -- Counts
    unread_count INT DEFAULT 0,
    total_messages INT DEFAULT 0,

    -- Timestamps
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(user_id, other_user_id)
);

CREATE INDEX idx_conversations_user ON message_conversations_denorm(user_id, last_message_time DESC);
CREATE INDEX idx_conversations_unread ON message_conversations_denorm(user_id, unread_count) WHERE unread_count > 0;
```

**Triggers:**
```sql
CREATE OR REPLACE FUNCTION update_conversation_on_message()
RETURNS TRIGGER AS $$
BEGIN
    -- Update sender's conversation view
    INSERT INTO message_conversations_denorm (
        user_id, other_user_id, last_message_id, last_message_text,
        last_message_time, last_sender_id, total_messages
    )
    VALUES (
        NEW.sender_id, NEW.recipient_id, NEW.id, NEW.message,
        NEW.created_at, NEW.sender_id, 1
    )
    ON CONFLICT (user_id, other_user_id) DO UPDATE
    SET last_message_id = NEW.id,
        last_message_text = NEW.message,
        last_message_time = NEW.created_at,
        last_sender_id = NEW.sender_id,
        total_messages = message_conversations_denorm.total_messages + 1,
        updated_at = CURRENT_TIMESTAMP;

    -- Update recipient's conversation view (with unread count)
    INSERT INTO message_conversations_denorm (
        user_id, other_user_id, last_message_id, last_message_text,
        last_message_time, last_sender_id, total_messages, unread_count
    )
    VALUES (
        NEW.recipient_id, NEW.sender_id, NEW.id, NEW.message,
        NEW.created_at, NEW.sender_id, 1, 1
    )
    ON CONFLICT (user_id, other_user_id) DO UPDATE
    SET last_message_id = NEW.id,
        last_message_text = NEW.message,
        last_message_time = NEW.created_at,
        last_sender_id = NEW.sender_id,
        total_messages = message_conversations_denorm.total_messages + 1,
        unread_count = message_conversations_denorm.unread_count + 1,
        updated_at = CURRENT_TIMESTAMP;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_conversation_on_message
AFTER INSERT ON direct_messages
FOR EACH ROW EXECUTE FUNCTION update_conversation_on_message();

-- Trigger for marking as read
CREATE OR REPLACE FUNCTION update_conversation_on_read()
RETURNS TRIGGER AS $$
BEGIN
    IF OLD.is_read = FALSE AND NEW.is_read = TRUE THEN
        UPDATE message_conversations_denorm
        SET unread_count = GREATEST(0, unread_count - 1),
            updated_at = CURRENT_TIMESTAMP
        WHERE user_id = NEW.recipient_id AND other_user_id = NEW.sender_id;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_conversation_on_read
AFTER UPDATE ON direct_messages
FOR EACH ROW EXECUTE FUNCTION update_conversation_on_read();
```

---

### 3. Intro Request Stats (`intro_request_stats`)
**Purpose:** Fast counts for intro request badges

```sql
CREATE TABLE intro_request_stats (
    user_id UUID PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE,

    -- As builder (receiving requests)
    pending_requests INT DEFAULT 0,
    approved_requests INT DEFAULT 0,
    rejected_requests INT DEFAULT 0,

    -- As investor (sending requests)
    sent_requests INT DEFAULT 0,

    last_updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_intro_stats_pending ON intro_request_stats(user_id, pending_requests) WHERE pending_requests > 0;
```

**Triggers:**
```sql
CREATE OR REPLACE FUNCTION update_intro_request_stats()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        -- Increment pending for builder
        INSERT INTO intro_request_stats (user_id, pending_requests, sent_requests)
        VALUES (NEW.builder_id, 1, 0)
        ON CONFLICT (user_id) DO UPDATE
        SET pending_requests = intro_request_stats.pending_requests + 1,
            last_updated_at = CURRENT_TIMESTAMP;

        -- Increment sent for investor
        INSERT INTO intro_request_stats (user_id, pending_requests, sent_requests)
        VALUES (NEW.investor_id, 0, 1)
        ON CONFLICT (user_id) DO UPDATE
        SET sent_requests = intro_request_stats.sent_requests + 1,
            last_updated_at = CURRENT_TIMESTAMP;

    ELSIF TG_OP = 'UPDATE' AND OLD.status != NEW.status THEN
        -- Status changed, update builder stats
        IF OLD.status = 'pending' THEN
            UPDATE intro_request_stats
            SET pending_requests = GREATEST(0, pending_requests - 1),
                approved_requests = CASE WHEN NEW.status = 'approved' THEN approved_requests + 1 ELSE approved_requests END,
                rejected_requests = CASE WHEN NEW.status = 'rejected' THEN rejected_requests + 1 ELSE rejected_requests END,
                last_updated_at = CURRENT_TIMESTAMP
            WHERE user_id = NEW.builder_id;
        END IF;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_intro_request_stats
AFTER INSERT OR UPDATE ON intro_requests
FOR EACH ROW EXECUTE FUNCTION update_intro_request_stats();
```

---

## üìä Materialized Views (Category B)

### 1. Feed View (`mv_feed_projects`)
**Purpose:** Pre-compute feed with all metadata for instant load

```sql
CREATE MATERIALIZED VIEW mv_feed_projects AS
SELECT
    p.id,
    p.title,
    p.description,
    p.proof_of_work_link,
    p.image_url,
    p.created_at,
    p.updated_at,
    p.is_featured,
    p.category,

    -- Creator info (denormalized)
    p.user_id,
    u.username,
    u.profile_image,
    u.is_verified,

    -- Engagement metrics (pre-computed)
    p.proof_score,
    (SELECT COUNT(*) FROM comments WHERE project_id = p.id AND parent_id IS NULL) as comment_count,
    (SELECT COUNT(*) FROM upvotes WHERE project_id = p.id AND is_upvote = TRUE) as upvote_count,
    (SELECT COUNT(*) FROM validation_badges WHERE project_id = p.id) as badge_count,

    -- User-specific data placeholder (filled at query time)
    FALSE as user_has_upvoted,

    -- Trending score (for sorting)
    (
        p.proof_score * 0.5 +
        (SELECT COUNT(*) FROM comments WHERE project_id = p.id) * 2 +
        (SELECT COUNT(*) FROM upvotes WHERE project_id = p.id) * 1.5 +
        EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - p.created_at)) / 3600 * -0.1
    ) as trending_score

FROM projects p
JOIN users u ON p.user_id = u.id
WHERE p.is_deleted = FALSE
ORDER BY trending_score DESC;

-- Indexes on materialized view
CREATE UNIQUE INDEX idx_mv_feed_id ON mv_feed_projects(id);
CREATE INDEX idx_mv_feed_trending ON mv_feed_projects(trending_score DESC);
CREATE INDEX idx_mv_feed_proof_score ON mv_feed_projects(proof_score DESC);
CREATE INDEX idx_mv_feed_created ON mv_feed_projects(created_at DESC);
CREATE INDEX idx_mv_feed_category ON mv_feed_projects(category, trending_score DESC);
CREATE INDEX idx_mv_feed_featured ON mv_feed_projects(is_featured, trending_score DESC) WHERE is_featured = TRUE;
```

**Refresh Triggers:**
```sql
-- Refresh on project changes
CREATE OR REPLACE FUNCTION refresh_feed_on_project_change()
RETURNS TRIGGER AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_feed_projects;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_refresh_feed_project
AFTER INSERT OR UPDATE OR DELETE ON projects
FOR EACH STATEMENT EXECUTE FUNCTION refresh_feed_on_project_change();

-- Refresh on vote
CREATE TRIGGER trg_refresh_feed_vote
AFTER INSERT OR DELETE ON upvotes
FOR EACH STATEMENT EXECUTE FUNCTION refresh_feed_on_project_change();

-- Refresh on badge award
CREATE TRIGGER trg_refresh_feed_badge
AFTER INSERT ON validation_badges
FOR EACH STATEMENT EXECUTE FUNCTION refresh_feed_on_project_change();

-- Refresh on comment (affects trending)
CREATE TRIGGER trg_refresh_feed_comment
AFTER INSERT ON comments
FOR EACH STATEMENT EXECUTE FUNCTION refresh_feed_on_project_change();
```

**Backend Query (Fast):**
```python
# Instead of complex JOIN query, just read from materialized view
def get_feed_fast(sort='trending', page=1, limit=10):
    query = db.session.query(MVFeedProjects)

    if sort == 'trending':
        query = query.order_by(MVFeedProjects.trending_score.desc())
    elif sort == 'top-rated':
        query = query.order_by(MVFeedProjects.proof_score.desc())
    elif sort == 'newest':
        query = query.order_by(MVFeedProjects.created_at.desc())

    # Fast pagination (index-backed)
    projects = query.offset((page - 1) * limit).limit(limit).all()

    # Fill user-specific data (if authenticated)
    if user_id:
        project_ids = [p.id for p in projects]
        user_upvotes = set(
            db.session.query(Upvote.project_id)
            .filter(Upvote.user_id == user_id, Upvote.project_id.in_(project_ids))
            .scalar_all()
        )
        for p in projects:
            p.user_has_upvoted = p.id in user_upvotes

    return projects
```

---

### 2. Leaderboard Views

#### Projects Leaderboard (`mv_leaderboard_projects`)
```sql
CREATE MATERIALIZED VIEW mv_leaderboard_projects AS
SELECT
    p.id,
    p.title,
    p.image_url,
    p.proof_score,
    p.user_id,
    u.username,
    u.profile_image,

    -- Metrics
    (SELECT COUNT(*) FROM validation_badges WHERE project_id = p.id) as badge_count,
    (SELECT COUNT(*) FROM comments WHERE project_id = p.id) as comment_count,
    (SELECT COUNT(*) FROM upvotes WHERE project_id = p.id) as vote_count,

    -- Rank (computed on refresh)
    ROW_NUMBER() OVER (ORDER BY p.proof_score DESC, p.created_at ASC) as rank

FROM projects p
JOIN users u ON p.user_id = u.id
WHERE p.is_deleted = FALSE AND p.proof_score > 0
ORDER BY p.proof_score DESC
LIMIT 1000;

CREATE UNIQUE INDEX idx_mv_leaderboard_projects_id ON mv_leaderboard_projects(id);
CREATE INDEX idx_mv_leaderboard_projects_rank ON mv_leaderboard_projects(rank);
CREATE INDEX idx_mv_leaderboard_projects_score ON mv_leaderboard_projects(proof_score DESC);
```

#### Builders Leaderboard (`mv_leaderboard_builders`)
```sql
CREATE MATERIALIZED VIEW mv_leaderboard_builders AS
SELECT
    u.id,
    u.username,
    u.profile_image,
    u.bio,
    u.is_verified,

    -- Karma (main metric)
    COALESCE(
        (SELECT SUM(p.proof_score) FROM projects p WHERE p.user_id = u.id AND p.is_deleted = FALSE),
        0
    ) as total_karma,

    -- Supporting metrics
    (SELECT COUNT(*) FROM projects WHERE user_id = u.id AND is_deleted = FALSE) as project_count,
    (SELECT COUNT(*) FROM validation_badges WHERE validator_id = u.id) as badges_given,
    (SELECT COUNT(*) FROM comments WHERE user_id = u.id) as comment_count,

    -- Rank
    ROW_NUMBER() OVER (
        ORDER BY (
            SELECT COALESCE(SUM(p.proof_score), 0)
            FROM projects p
            WHERE p.user_id = u.id AND p.is_deleted = FALSE
        ) DESC
    ) as rank

FROM users u
WHERE u.is_active = TRUE
ORDER BY total_karma DESC
LIMIT 1000;

CREATE UNIQUE INDEX idx_mv_leaderboard_builders_id ON mv_leaderboard_builders(id);
CREATE INDEX idx_mv_leaderboard_builders_rank ON mv_leaderboard_builders(rank);
CREATE INDEX idx_mv_leaderboard_builders_karma ON mv_leaderboard_builders(total_karma DESC);
```

**Refresh Triggers:**
```sql
-- Refresh leaderboards on badge award (affects both project and builder rankings)
CREATE OR REPLACE FUNCTION refresh_leaderboards()
RETURNS TRIGGER AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_leaderboard_projects;
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_leaderboard_builders;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_refresh_leaderboards_badge
AFTER INSERT ON validation_badges
FOR EACH STATEMENT EXECUTE FUNCTION refresh_leaderboards();

-- Refresh on project proof_score change
CREATE TRIGGER trg_refresh_leaderboards_project
AFTER UPDATE OF proof_score ON projects
FOR EACH STATEMENT EXECUTE FUNCTION refresh_leaderboards();
```

---

### 3. Chains Discovery (`mv_chains_discovery`)
```sql
CREATE MATERIALIZED VIEW mv_chains_discovery AS
SELECT
    c.id,
    c.name,
    c.description,
    c.image_url,
    c.category,
    c.is_public,
    c.is_featured,
    c.created_at,

    -- Creator info
    c.creator_id,
    u.username as creator_username,
    u.profile_image as creator_profile_image,

    -- Metrics (pre-computed)
    (SELECT COUNT(*) FROM chain_followers WHERE chain_id = c.id) as follower_count,
    (SELECT COUNT(*) FROM chain_projects WHERE chain_id = c.id) as project_count,
    (SELECT COUNT(*) FROM chain_posts WHERE chain_id = c.id) as post_count,

    -- Trending score
    (
        (SELECT COUNT(*) FROM chain_followers WHERE chain_id = c.id) * 0.3 +
        (SELECT COUNT(*) FROM chain_projects WHERE chain_id = c.id) * 0.6 +
        (SELECT COUNT(*) FROM chain_posts WHERE chain_id = c.id AND created_at > CURRENT_TIMESTAMP - INTERVAL '7 days') * 0.1
    ) as trending_score,

    -- User-specific (filled at query time)
    FALSE as user_is_following

FROM chains c
JOIN users u ON c.creator_id = u.id
WHERE c.is_active = TRUE
ORDER BY trending_score DESC;

CREATE UNIQUE INDEX idx_mv_chains_id ON mv_chains_discovery(id);
CREATE INDEX idx_mv_chains_trending ON mv_chains_discovery(trending_score DESC);
CREATE INDEX idx_mv_chains_followers ON mv_chains_discovery(follower_count DESC);
CREATE INDEX idx_mv_chains_category ON mv_chains_discovery(category, trending_score DESC);
CREATE INDEX idx_mv_chains_featured ON mv_chains_discovery(is_featured, trending_score DESC) WHERE is_featured = TRUE;
```

**Refresh Triggers:**
```sql
CREATE OR REPLACE FUNCTION refresh_chains_discovery()
RETURNS TRIGGER AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_chains_discovery;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_refresh_chains_meta
AFTER INSERT OR UPDATE ON chains
FOR EACH STATEMENT EXECUTE FUNCTION refresh_chains_discovery();

CREATE TRIGGER trg_refresh_chains_followers
AFTER INSERT OR DELETE ON chain_followers
FOR EACH STATEMENT EXECUTE FUNCTION refresh_chains_discovery();

CREATE TRIGGER trg_refresh_chains_projects
AFTER INSERT OR DELETE ON chain_projects
FOR EACH STATEMENT EXECUTE FUNCTION refresh_chains_discovery();

CREATE TRIGGER trg_refresh_chains_posts
AFTER INSERT ON chain_posts
FOR EACH STATEMENT EXECUTE FUNCTION refresh_chains_discovery();
```

---

### 4. Chain Details & Forums (`mv_chain_posts`)
```sql
CREATE MATERIALIZED VIEW mv_chain_posts AS
SELECT
    cp.id,
    cp.chain_id,
    cp.title,
    cp.content,
    cp.post_type,
    cp.created_at,
    cp.updated_at,
    cp.is_pinned,

    -- Author info
    cp.author_id,
    u.username as author_username,
    u.profile_image as author_profile_image,
    u.is_verified as author_is_verified,

    -- Engagement metrics
    (SELECT COUNT(*) FROM chain_post_votes WHERE post_id = cp.id AND is_upvote = TRUE) as upvote_count,
    (SELECT COUNT(*) FROM chain_post_comments WHERE post_id = cp.id) as comment_count,

    -- Trending score
    (
        (SELECT COUNT(*) FROM chain_post_votes WHERE post_id = cp.id) * 1.5 +
        (SELECT COUNT(*) FROM chain_post_comments WHERE post_id = cp.id) * 2 +
        EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - cp.created_at)) / 3600 * -0.1
    ) as trending_score

FROM chain_posts cp
JOIN users u ON cp.author_id = u.id
WHERE cp.is_deleted = FALSE
ORDER BY cp.chain_id, cp.is_pinned DESC, trending_score DESC;

CREATE UNIQUE INDEX idx_mv_chain_posts_id ON mv_chain_posts(id);
CREATE INDEX idx_mv_chain_posts_chain ON mv_chain_posts(chain_id, is_pinned DESC, trending_score DESC);
CREATE INDEX idx_mv_chain_posts_trending ON mv_chain_posts(chain_id, trending_score DESC);
CREATE INDEX idx_mv_chain_posts_created ON mv_chain_posts(chain_id, created_at DESC);
```

**Refresh Triggers:**
```sql
CREATE OR REPLACE FUNCTION refresh_chain_posts()
RETURNS TRIGGER AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_chain_posts;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_refresh_chain_posts_meta
AFTER INSERT OR UPDATE ON chain_posts
FOR EACH STATEMENT EXECUTE FUNCTION refresh_chain_posts();

CREATE TRIGGER trg_refresh_chain_posts_votes
AFTER INSERT OR DELETE ON chain_post_votes
FOR EACH STATEMENT EXECUTE FUNCTION refresh_chain_posts();

CREATE TRIGGER trg_refresh_chain_posts_comments
AFTER INSERT ON chain_post_comments
FOR EACH STATEMENT EXECUTE FUNCTION refresh_chain_posts();
```

---

### 5. Investors Directory (`mv_investors_directory`)
```sql
CREATE MATERIALIZED VIEW mv_investors_directory AS
SELECT
    ir.id,
    ir.user_id,
    ir.status,
    ir.created_at,
    ir.approved_at,

    -- User info
    u.username,
    u.profile_image,
    u.bio,
    u.email,

    -- Investor details
    ir.company_name,
    ir.investment_focus,
    ir.ticket_size,
    ir.portfolio_url,
    ir.linkedin_url,

    -- Activity metrics
    (SELECT COUNT(*) FROM intro_requests WHERE investor_id = ir.user_id) as intro_requests_sent,
    (SELECT COUNT(*) FROM intro_requests WHERE investor_id = ir.user_id AND status = 'approved') as intros_approved

FROM investor_requests ir
JOIN users u ON ir.user_id = u.id
WHERE ir.status = 'approved'
ORDER BY ir.approved_at DESC;

CREATE UNIQUE INDEX idx_mv_investors_id ON mv_investors_directory(id);
CREATE INDEX idx_mv_investors_user ON mv_investors_directory(user_id);
CREATE INDEX idx_mv_investors_focus ON mv_investors_directory(investment_focus);
CREATE INDEX idx_mv_investors_approved ON mv_investors_directory(approved_at DESC);
```

**Refresh Triggers:**
```sql
CREATE OR REPLACE FUNCTION refresh_investors_directory()
RETURNS TRIGGER AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_investors_directory;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_refresh_investors_status
AFTER UPDATE OF status ON investor_requests
FOR EACH STATEMENT EXECUTE FUNCTION refresh_investors_directory();

CREATE TRIGGER trg_refresh_investors_intro
AFTER INSERT OR UPDATE ON intro_requests
FOR EACH STATEMENT EXECUTE FUNCTION refresh_investors_directory();
```

---

### 6. Project Details Page (`mv_project_details`)
```sql
CREATE MATERIALIZED VIEW mv_project_details AS
SELECT
    p.id,
    p.title,
    p.description,
    p.proof_of_work_link,
    p.image_url,
    p.category,
    p.created_at,
    p.updated_at,
    p.proof_score,

    -- Creator info
    p.user_id,
    u.username,
    u.profile_image,
    u.bio as creator_bio,
    u.is_verified,

    -- Engagement metrics (pre-computed)
    (SELECT COUNT(*) FROM comments WHERE project_id = p.id AND parent_id IS NULL) as comment_count,
    (SELECT COUNT(*) FROM upvotes WHERE project_id = p.id) as vote_count,
    (SELECT COUNT(*) FROM validation_badges WHERE project_id = p.id) as badge_count,

    -- Badges (JSON array for fast access)
    (
        SELECT JSON_AGG(
            JSON_BUILD_OBJECT(
                'id', vb.id,
                'badge_type', vb.badge_type,
                'validator_id', vb.validator_id,
                'validator_username', v.username,
                'created_at', vb.created_at
            )
        )
        FROM validation_badges vb
        JOIN users v ON vb.validator_id = v.id
        WHERE vb.project_id = p.id
    ) as badges_json,

    -- Chains this project is in (JSON array)
    (
        SELECT JSON_AGG(
            JSON_BUILD_OBJECT(
                'id', c.id,
                'name', c.name,
                'image_url', c.image_url
            )
        )
        FROM chain_projects cp
        JOIN chains c ON cp.chain_id = c.id
        WHERE cp.project_id = p.id
    ) as chains_json

FROM projects p
JOIN users u ON p.user_id = u.id
WHERE p.is_deleted = FALSE;

CREATE UNIQUE INDEX idx_mv_project_details_id ON mv_project_details(id);
CREATE INDEX idx_mv_project_details_user ON mv_project_details(user_id);
```

**Refresh Triggers:**
```sql
CREATE OR REPLACE FUNCTION refresh_project_details()
RETURNS TRIGGER AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_project_details;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Refresh on project update
CREATE TRIGGER trg_refresh_project_details_project
AFTER UPDATE ON projects
FOR EACH STATEMENT EXECUTE FUNCTION refresh_project_details();

-- Refresh on badge
CREATE TRIGGER trg_refresh_project_details_badge
AFTER INSERT ON validation_badges
FOR EACH STATEMENT EXECUTE FUNCTION refresh_project_details();

-- Refresh on chain addition
CREATE TRIGGER trg_refresh_project_details_chain
AFTER INSERT OR DELETE ON chain_projects
FOR EACH STATEMENT EXECUTE FUNCTION refresh_project_details();
```

---

### 7. Search Index (`mv_search_index`)
**Purpose:** Full-text search across projects, users, chains

```sql
-- Install pg_trgm extension for fuzzy search
CREATE EXTENSION IF NOT EXISTS pg_trgm;

CREATE MATERIALIZED VIEW mv_search_index AS
SELECT
    'project' as result_type,
    p.id,
    p.title as name,
    p.description,
    p.image_url,
    p.created_at,
    p.user_id,
    u.username as creator_username,
    p.proof_score as relevance_score,

    -- Full-text search vector
    TO_TSVECTOR('english',
        COALESCE(p.title, '') || ' ' ||
        COALESCE(p.description, '') || ' ' ||
        COALESCE(u.username, '')
    ) as search_vector

FROM projects p
JOIN users u ON p.user_id = u.id
WHERE p.is_deleted = FALSE

UNION ALL

SELECT
    'user' as result_type,
    u.id,
    u.username as name,
    u.bio as description,
    u.profile_image as image_url,
    u.created_at,
    u.id as user_id,
    u.username as creator_username,
    (SELECT COUNT(*) FROM projects WHERE user_id = u.id) as relevance_score,

    TO_TSVECTOR('english',
        COALESCE(u.username, '') || ' ' ||
        COALESCE(u.bio, '')
    ) as search_vector

FROM users u
WHERE u.is_active = TRUE

UNION ALL

SELECT
    'chain' as result_type,
    c.id,
    c.name,
    c.description,
    c.image_url,
    c.created_at,
    c.creator_id as user_id,
    u.username as creator_username,
    (SELECT COUNT(*) FROM chain_followers WHERE chain_id = c.id) as relevance_score,

    TO_TSVECTOR('english',
        COALESCE(c.name, '') || ' ' ||
        COALESCE(c.description, '')
    ) as search_vector

FROM chains c
JOIN users u ON c.creator_id = u.id
WHERE c.is_active = TRUE AND c.is_public = TRUE;

-- Indexes for fast search
CREATE INDEX idx_search_vector ON mv_search_index USING GIN(search_vector);
CREATE INDEX idx_search_type ON mv_search_index(result_type, relevance_score DESC);
CREATE INDEX idx_search_created ON mv_search_index(created_at DESC);
CREATE INDEX idx_search_name_trgm ON mv_search_index USING GIN(name gin_trgm_ops);
```

**Refresh Triggers:**
```sql
CREATE OR REPLACE FUNCTION refresh_search_index()
RETURNS TRIGGER AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_search_index;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Refresh on any content change
CREATE TRIGGER trg_refresh_search_project
AFTER INSERT OR UPDATE ON projects
FOR EACH STATEMENT EXECUTE FUNCTION refresh_search_index();

CREATE TRIGGER trg_refresh_search_user
AFTER UPDATE ON users
FOR EACH STATEMENT EXECUTE FUNCTION refresh_search_index();

CREATE TRIGGER trg_refresh_search_chain
AFTER INSERT OR UPDATE ON chains
FOR EACH STATEMENT EXECUTE FUNCTION refresh_search_index();
```

**Backend Search Query:**
```python
def search_fast(query, result_type=None, limit=20):
    """Fast search using materialized view with full-text search"""
    sql = text("""
        SELECT *,
               TS_RANK(search_vector, plainto_tsquery('english', :query)) as rank
        FROM mv_search_index
        WHERE search_vector @@ plainto_tsquery('english', :query)
          AND (:type IS NULL OR result_type = :type)
        ORDER BY rank DESC, relevance_score DESC
        LIMIT :limit
    """)

    results = db.session.execute(sql, {
        'query': query,
        'type': result_type,
        'limit': limit
    }).fetchall()

    return [dict(row) for row in results]
```

---

## üîç Missing Critical Indexes

### Core Tables
```sql
-- Projects table
CREATE INDEX IF NOT EXISTS idx_projects_user_deleted ON projects(user_id, is_deleted) WHERE is_deleted = FALSE;
CREATE INDEX IF NOT EXISTS idx_projects_category_score ON projects(category, proof_score DESC) WHERE is_deleted = FALSE;
CREATE INDEX IF NOT EXISTS idx_projects_featured ON projects(is_featured, created_at DESC) WHERE is_featured = TRUE;

-- Users table
CREATE INDEX IF NOT EXISTS idx_users_username_lower ON users(LOWER(username));
CREATE INDEX IF NOT EXISTS idx_users_email_lower ON users(LOWER(email));
CREATE INDEX IF NOT EXISTS idx_users_active ON users(is_active) WHERE is_active = TRUE;

-- Comments table
CREATE INDEX IF NOT EXISTS idx_comments_project_parent ON comments(project_id, parent_id, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_comments_user ON comments(user_id, created_at DESC);

-- Upvotes table
CREATE INDEX IF NOT EXISTS idx_upvotes_user_project ON upvotes(user_id, project_id);
CREATE INDEX IF NOT EXISTS idx_upvotes_project ON upvotes(project_id) WHERE is_upvote = TRUE;

-- Validation badges
CREATE INDEX IF NOT EXISTS idx_badges_project ON validation_badges(project_id, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_badges_validator ON validation_badges(validator_id, created_at DESC);

-- Direct messages
CREATE INDEX IF NOT EXISTS idx_messages_conversation ON direct_messages(sender_id, recipient_id, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_messages_unread ON direct_messages(recipient_id, is_read, created_at DESC) WHERE is_read = FALSE;

-- Notifications
CREATE INDEX IF NOT EXISTS idx_notifications_user_unread ON notifications(user_id, is_read, created_at DESC) WHERE is_read = FALSE;
CREATE INDEX IF NOT EXISTS idx_notifications_user_created ON notifications(user_id, created_at DESC);

-- Chains
CREATE INDEX IF NOT EXISTS idx_chains_creator ON chains(creator_id, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_chains_public_active ON chains(is_public, is_active) WHERE is_public = TRUE AND is_active = TRUE;

-- Chain followers
CREATE INDEX IF NOT EXISTS idx_chain_followers_user ON chain_followers(user_id, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_chain_followers_chain ON chain_followers(chain_id, created_at DESC);

-- Chain posts
CREATE INDEX IF NOT EXISTS idx_chain_posts_chain ON chain_posts(chain_id, is_pinned DESC, created_at DESC) WHERE is_deleted = FALSE;
CREATE INDEX IF NOT EXISTS idx_chain_posts_author ON chain_posts(author_id, created_at DESC);

-- Intro requests
CREATE INDEX IF NOT EXISTS idx_intro_requests_builder_status ON intro_requests(builder_id, status, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_intro_requests_investor ON intro_requests(investor_id, created_at DESC);

-- Investor requests
CREATE INDEX IF NOT EXISTS idx_investor_requests_status ON investor_requests(status, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_investor_requests_user ON investor_requests(user_id);
```

---

## üöÄ Migration Plan

### Phase 1: Create Denormalized Tables (Week 1)
1. Create `user_dashboard_stats` table + triggers
2. Create `message_conversations_denorm` table + triggers
3. Create `intro_request_stats` table + triggers
4. Backfill data from existing tables
5. Update backend routes to query new tables

### Phase 2: Create Materialized Views (Week 2)
1. Create `mv_feed_projects` + refresh triggers
2. Create `mv_leaderboard_projects` + `mv_leaderboard_builders` + triggers
3. Create `mv_chains_discovery` + triggers
4. Create `mv_project_details` + triggers
5. Update backend routes to query materialized views

### Phase 3: Search & Chain Forums (Week 3)
1. Install pg_trgm extension
2. Create `mv_search_index` + refresh triggers
3. Create `mv_chain_posts` + refresh triggers
4. Create `mv_investors_directory` + triggers
5. Update search and forum routes

### Phase 4: Add Missing Indexes (Week 4)
1. Run index creation scripts (non-blocking with CONCURRENTLY)
2. Analyze query performance with EXPLAIN ANALYZE
3. Add additional indexes based on slow query log

### Phase 5: Testing & Optimization (Week 5)
1. Load test with 5000 concurrent users
2. Monitor materialized view refresh times
3. Optimize trigger performance
4. Add caching layer (Redis) for ultra-hot paths
5. Document all changes

---

## üìà Expected Performance Impact

### Before (Current State)
| Page | Load Time | Query Count | Database Hits |
|------|-----------|-------------|---------------|
| Feed | 800ms | 15 queries | 50+ rows scanned |
| Leaderboard | 1200ms | 8 queries | 10,000+ rows |
| Dashboard | 600ms | 12 queries | 100+ rows |
| Chains List | 500ms | 6 queries | 500+ rows |
| Search | 1500ms | 10 queries | Full table scan |
| Project Details | 700ms | 18 queries | 200+ rows |

### After (With Denormalization)
| Page | Load Time | Query Count | Database Hits |
|------|-----------|-------------|---------------|
| Feed | **120ms** ‚ö° | 2 queries | 10 rows (MV) |
| Leaderboard | **80ms** ‚ö° | 1 query | 50 rows (MV) |
| Dashboard | **50ms** ‚ö° | 1 query | 1 row (denorm) |
| Chains List | **90ms** ‚ö° | 1 query | 12 rows (MV) |
| Search | **150ms** ‚ö° | 1 query | Index scan |
| Project Details | **100ms** ‚ö° | 2 queries | 1 row (MV) + comments |

**Overall Improvement:** 5-10x faster across all pages

---

## ‚öôÔ∏è Backend Implementation Changes

### Route Updates Required
```python
# OLD: Complex JOIN query
@projects_bp.route('', methods=['GET'])
def get_feed_old():
    projects = db.session.query(Project)\
        .join(User)\
        .outerjoin(Comment)\
        .outerjoin(Upvote)\
        .group_by(Project.id)\
        .order_by(...)  # Complex sorting
    # ... 50 lines of code

# NEW: Simple materialized view query
@projects_bp.route('', methods=['GET'])
def get_feed_new():
    projects = db.session.query(MVFeedProjects)\
        .order_by(MVFeedProjects.trending_score.desc())\
        .limit(10).all()
    # ... 5 lines of code
```

### Service Layer
```python
# services/denormalized_data.py
class DenormalizedDataService:
    @staticmethod
    def get_user_dashboard(user_id):
        """Get dashboard stats from denormalized table"""
        stats = UserDashboardStats.query.get(user_id)
        if not stats:
            # Create if doesn't exist (new user)
            stats = UserDashboardStats(user_id=user_id)
            db.session.add(stats)
            db.session.commit()
        return stats.to_dict()

    @staticmethod
    def get_message_conversations(user_id, limit=20):
        """Get conversation list from denormalized table"""
        conversations = MessageConversationsDenorm.query\
            .filter_by(user_id=user_id)\
            .order_by(MessageConversationsDenorm.last_message_time.desc())\
            .limit(limit).all()
        return [c.to_dict() for c in conversations]

    @staticmethod
    def get_feed_fast(sort='trending', page=1, limit=10, user_id=None):
        """Get feed from materialized view"""
        query = db.session.query(MVFeedProjects)

        if sort == 'trending':
            query = query.order_by(MVFeedProjects.trending_score.desc())
        elif sort == 'top-rated':
            query = query.order_by(MVFeedProjects.proof_score.desc())
        elif sort == 'newest':
            query = query.order_by(MVFeedProjects.created_at.desc())

        projects = query.offset((page - 1) * limit).limit(limit).all()

        # Fill user-specific data if authenticated
        if user_id:
            fill_user_specific_data(projects, user_id)

        return projects
```

---

## üîí Consistency Guarantees

### Real-Time Tables (Trigger-Based)
- **Consistency:** Immediate (within transaction)
- **Latency:** 0ms (synchronous)
- **Use Case:** Critical user-facing data

### Materialized Views (Event-Driven Refresh)
- **Consistency:** Eventually consistent (1-5 seconds)
- **Latency:** Refresh time varies (50ms - 500ms depending on data size)
- **Use Case:** Public discovery, analytics

### Refresh Strategy
```sql
-- CONCURRENTLY: Non-blocking refresh (requires UNIQUE index)
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_feed_projects;

-- Refresh time estimates (5000 users, 10,000 projects):
-- mv_feed_projects: ~200ms
-- mv_leaderboard_projects: ~100ms
-- mv_leaderboard_builders: ~150ms
-- mv_chains_discovery: ~80ms
-- mv_search_index: ~300ms
```

---

## üìä Monitoring & Maintenance

### View Refresh Monitoring
```sql
-- Track materialized view refresh times
CREATE TABLE mv_refresh_log (
    id SERIAL PRIMARY KEY,
    view_name TEXT NOT NULL,
    refresh_started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    refresh_completed_at TIMESTAMP,
    duration_ms INT,
    row_count BIGINT,
    triggered_by TEXT,
    status TEXT DEFAULT 'pending'
);

-- Add to each refresh trigger
CREATE OR REPLACE FUNCTION log_mv_refresh(view_name TEXT)
RETURNS VOID AS $$
DECLARE
    start_time TIMESTAMP;
    end_time TIMESTAMP;
    row_cnt BIGINT;
BEGIN
    start_time := CLOCK_TIMESTAMP();
    EXECUTE format('REFRESH MATERIALIZED VIEW CONCURRENTLY %I', view_name);
    end_time := CLOCK_TIMESTAMP();
    EXECUTE format('SELECT COUNT(*) FROM %I', view_name) INTO row_cnt;

    INSERT INTO mv_refresh_log (view_name, refresh_started_at, refresh_completed_at, duration_ms, row_count, status)
    VALUES (view_name, start_time, end_time, EXTRACT(EPOCH FROM (end_time - start_time)) * 1000, row_cnt, 'completed');
END;
$$ LANGUAGE plpgsql;
```

### Health Check Endpoint
```python
@admin_bp.route('/denormalization-health', methods=['GET'])
@token_required
def denormalization_health(user_id):
    """Check health of denormalized data structures"""
    if not User.query.get(user_id).is_admin:
        return error_response('Forbidden', 'Admin only', 403)

    health = {
        'materialized_views': {},
        'denormalized_tables': {},
        'recent_refreshes': []
    }

    # Check materialized view stats
    views = ['mv_feed_projects', 'mv_leaderboard_projects', 'mv_leaderboard_builders',
             'mv_chains_discovery', 'mv_project_details', 'mv_search_index', 'mv_chain_posts']

    for view in views:
        result = db.session.execute(text(f"SELECT COUNT(*) FROM {view}")).scalar()
        health['materialized_views'][view] = {'row_count': result, 'status': 'healthy'}

    # Check denormalized table stats
    health['denormalized_tables']['user_dashboard_stats'] = {
        'row_count': UserDashboardStats.query.count(),
        'status': 'healthy'
    }
    health['denormalized_tables']['message_conversations_denorm'] = {
        'row_count': MessageConversationsDenorm.query.count(),
        'status': 'healthy'
    }

    # Get recent refresh logs
    recent_refreshes = db.session.execute(text("""
        SELECT view_name, refresh_completed_at, duration_ms, row_count
        FROM mv_refresh_log
        WHERE status = 'completed'
        ORDER BY refresh_completed_at DESC
        LIMIT 10
    """)).fetchall()

    health['recent_refreshes'] = [
        {
            'view': r[0],
            'completed_at': r[1].isoformat(),
            'duration_ms': r[2],
            'row_count': r[3]
        }
        for r in recent_refreshes
    ]

    return success_response(health, 'Denormalization health check', 200)
```

---

## ‚úÖ Summary

### Real-Time (Triggers)
1. ‚úÖ User Dashboard Stats
2. ‚úÖ Message Conversations
3. ‚úÖ Intro Request Stats
4. ‚úÖ Unread Counts

### Eventually Consistent (Materialized Views)
1. ‚úÖ Feed (Trending/Top-Rated/Newest)
2. ‚úÖ Leaderboards (Projects/Builders)
3. ‚úÖ Chains Discovery
4. ‚úÖ Chain Details & Forums
5. ‚úÖ Investors Directory
6. ‚úÖ Project Details
7. ‚úÖ Search Index

### Indexes
1. ‚úÖ All missing critical indexes identified and scripted

### Migration Plan
1. ‚úÖ 5-week phased rollout
2. ‚úÖ Non-blocking migrations
3. ‚úÖ Load testing included

### Expected Results
- **10x faster page loads** (800ms ‚Üí 80ms average)
- **90% reduction in database load**
- **5000 concurrent users supported**
- **Sub-200ms response times** across all pages

---

## ü§î Discussion Points

1. **Materialized View Refresh Frequency**
   - Current: Event-driven (refresh on every data change)
   - Alternative: Debounced (refresh max once per 5 seconds)
   - Question: Should we debounce to avoid excessive refreshes during high traffic?

2. **User-Specific Data in Materialized Views**
   - Current: Filled at query time (user_has_upvoted, user_is_following)
   - Alternative: Store per-user in Redis cache
   - Question: Is query-time fill acceptable or should we cache?

3. **Backup Strategy for Denormalized Data**
   - Current: Triggers ensure consistency
   - Alternative: Periodic reconciliation job to verify correctness
   - Question: Should we add a nightly reconciliation job?

4. **Fallback on Refresh Failure**
   - Current: Continue serving stale data
   - Alternative: Fall back to live query
   - Question: What's the fallback strategy if materialized view refresh fails?

**Ready to implement? Let's discuss these points and I'll start creating migration scripts.**
